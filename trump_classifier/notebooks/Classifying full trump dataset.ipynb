{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crazy Data Loading (bad csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 686 multipart messages\n",
      "Threw away 184 multipart messages without match\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-06-16 12:20:40</td>\n",
       "      <td>Big time in U.S. today - MAKE AMERICA GREAT AG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-06-16 12:24:41</td>\n",
       "      <td>Thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-06-16 13:04:05</td>\n",
       "      <td>It is almost time. I will be making a major an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-16 13:07:50</td>\n",
       "      <td>Make sure to follow me on @periscopeco #MakeAm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-06-16 14:01:13</td>\n",
       "      <td>In one hour I will be making a major announcem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at                                               text\n",
       "0 2015-06-16 12:20:40  Big time in U.S. today - MAKE AMERICA GREAT AG...\n",
       "1 2015-06-16 12:24:41                                           Thanks. \n",
       "2 2015-06-16 13:04:05  It is almost time. I will be making a major an...\n",
       "3 2015-06-16 13:07:50  Make sure to follow me on @periscopeco #MakeAm...\n",
       "4 2015-06-16 14:01:13  In one hour I will be making a major announcem..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/trump_twitter_20150616_20190819.csv\", 'r') as f:\n",
    "    lines = f.readlines()[::-1]\n",
    "    \n",
    "combined_counter = 0\n",
    "parsed_lines = []\n",
    "for line in lines[:-1]:\n",
    "    output_line = line.strip().split(\"|\")\n",
    "    \n",
    "    # Fix bad splits\n",
    "    if len(output_line) > 2:\n",
    "        output_line = [\"|\".join(output_line[:-1]), output_line[-1]]\n",
    "    \n",
    "    # Combine multipart messages\n",
    "    if re.findall(r\"^\\.{2,}\", output_line[0]) and re.findall(r\"\\.{2,}$\", parsed_lines[-1][0]):\n",
    "        first_cleaned = re.sub(\"^\\.{2,}\", \" \", parsed_lines[-1][0])\n",
    "        second_cleaned = re.sub(\"^\\.{2,}\", \"\", output_line[0])\n",
    "        parsed_lines[-1][0] = first_cleaned + second_cleaned\n",
    "        combined_counter += 1\n",
    "        continue\n",
    "        \n",
    "    parsed_lines.append(output_line)\n",
    "    \n",
    "url_regex = r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\"\n",
    "    \n",
    "twitter_df = (\n",
    "    pd.DataFrame({\n",
    "        \"created_at\": [x[1] for x in parsed_lines],\n",
    "        \"text\": [x[0] for x in parsed_lines]\n",
    "    })\n",
    "    .assign(created_at=lambda x: pd.to_datetime(x.created_at, infer_datetime_format=True))\n",
    "    .assign(text=lambda x: x.text.str.replace(\"&amp;\", \"&\").str.replace(url_regex, \"\", regex=True))\n",
    ")\n",
    "\n",
    "startswith_dots = twitter_df.text.apply(lambda x: len(re.findall(\"^[\\.]{2,}\", x))) > 0\n",
    "endswith_dots = twitter_df.text.apply(lambda x: len(re.findall(\"[\\.]{2,}$\", x))) > 0\n",
    "\n",
    "twitter_df = twitter_df[~startswith_dots & ~endswith_dots]\n",
    "\n",
    "print(f\"Combined {combined_counter} multipart messages\")\n",
    "print(f\"Threw away {sum(startswith_dots) + sum(endswith_dots)} multipart messages without match\")\n",
    "\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Pretrained Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def identity(value):\n",
    "    return value\n",
    "\n",
    "class NERFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, spacy_model):\n",
    "        self.spacy_model = spacy_model\n",
    "        self.nlp = spacy.load(spacy_model, disable=[\"parser\", \"ner\"])\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return [[token.tag_ for token in doc] for doc in self.nlp.pipe(X)]\n",
    "    \n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "clf = joblib.load(\"../models/trump_classifer_095AUC.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_trump_ind = clf.predict(twitter_df)\n",
    "real_twitter_df = twitter_df[real_trump_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realtrump rowsl: 6332\n",
      "Percentage of original real: 0.51\n"
     ]
    }
   ],
   "source": [
    "print(f\"Realtrump rows: {len(real_twitter_df)}\")\n",
    "print(f\"Percentage of original real: {len(real_twitter_df)/len(twitter_df):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big time in U.S. today - MAKE AMERICA GREAT AGAIN! Politicians are all talk and no action - they can never bring us back. \n",
      "\n",
      "I am officially running for President of the United States. #MakeAmericaGreatAgain  \n",
      "\n",
      "@ericbolling, in addition,no doubt you would have been amazing on @ApprenticeNBC! Keep up the great work. \n",
      "\n",
      "Trump Int'l Hotel & Tower, Chicago, has received accolades for design, service & our signature restaurant, \"Sixteen\"  \n",
      "\n",
      "Just watched Brian Williams on @TODAYshow - very sad! Brian should get on with a new life and not start all over at @msnbc. Stop apologizing \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in real_twitter_df.text[:5]:\n",
    "    print(msg,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/trumpbot_training_data.txt\", 'w') as f:\n",
    "    f.writelines(\"\\n\".join(real_twitter_df.text.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
